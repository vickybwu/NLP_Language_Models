{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-GlnOpsTvmW"
      },
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "et5Ckx05UE65"
      },
      "outputs": [],
      "source": [
        "import requests as req\n",
        "# # read in both train and test data\n",
        "url_train = 'https://raw.githubusercontent.com/vickybwu/Myfiles/main/train.txt'\n",
        "res = req.get(url_train)\n",
        "train_data = res.text\n",
        "\n",
        "url_test = 'https://raw.githubusercontent.com/vickybwu/Myfiles/main/test.txt'\n",
        "ress = req.get(url_test)\n",
        "test_data = ress.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jk-KNEewzGU8"
      },
      "outputs": [],
      "source": [
        "# split the corpus into sentences \n",
        "train_data_sentenced = train_data.split('\\n')[: -1]\n",
        "test_data_sentenced = test_data.split('\\n')[: -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6fiNs8RgAPN4"
      },
      "outputs": [],
      "source": [
        "# pad the training data\n",
        "begin_token = '<s> '\n",
        "end_token = ' </s>'\n",
        "train_data_padded = list(map(lambda x: begin_token + x + end_token, train_data_sentenced))\n",
        "\n",
        "# pad the testing data \n",
        "test_data_padded = list(map(lambda x: begin_token + x + end_token, test_data_sentenced))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ov61a_cLHSOm"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "## split the padded training coupus into words\n",
        "trained_words = []\n",
        "for sen in train_data_padded:\n",
        "  words = sen.lower().split(' ')\n",
        "  trained_words += words\n",
        "  # for word in words:\n",
        "  #   if word == '<s>' or word == '</s>':\n",
        "  #     trained_words.append(word)\n",
        "  #   else:\n",
        "  #     word = word.strip(punctuation)\n",
        "  #     if word != '':\n",
        "  #       trained_words.append(word)\n",
        "\n",
        "## split the padded testing coupus into words\n",
        "test_words = []\n",
        "for sen in test_data_padded:\n",
        "  words = sen.lower().split(' ')\n",
        "  test_words += words\n",
        "  # for word in words:\n",
        "  #   if word == '<s>' or word == '</s>':\n",
        "  #     test_words.append(word)\n",
        "  #   else:\n",
        "  #     word = word.strip(punctuation)\n",
        "  #     if word != '':\n",
        "  #       test_words.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_words = {}\n",
        "for word in trained_words:\n",
        "  if word not in unique_words.keys():\n",
        "    unique_words[word] = 1\n",
        "  else:\n",
        "    unique_words[word] += 1\n",
        "\n",
        "unk_words = [key for key,value in unique_words.items() if value == 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkljV99OQF8U"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddDtD1_NArBH",
        "outputId": "07aa93ea-5d9f-47d9-b94c-344055d5b785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total word types in the training corpus is: 41738\n"
          ]
        }
      ],
      "source": [
        "# question 1\n",
        "total_word_type_count = len(list(unique_words.keys())) # including start and end symbol\n",
        "unk_word_count = len(unk_words)\n",
        "word_type_count = total_word_type_count - unk_word_count -1 + 1 # exluding start symbol and including <unk>\n",
        "print(\"The total word types in the training corpus is:\", word_type_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwSWluPER5Uk"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c72xyXvB38zW",
        "outputId": "081b85a5-a069-446e-edde-8fa79a6358cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total token count excluding the start symbol is: 2468210\n"
          ]
        }
      ],
      "source": [
        "total_token_count = len(trained_words)\n",
        "start_symbol_count = unique_words['<s>']\n",
        "total_token_without_start_count = total_token_count - start_symbol_count\n",
        "print(\"The total token count excluding the start symbol is:\",total_token_without_start_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh_0_yvmWvA5"
      },
      "source": [
        "### Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrtGHyn28n5a",
        "outputId": "c9458f7a-2b79-4b18-a092-8eb07ee1ddfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.61% of word types in the testing data is not in the training data (excluding the start symbol)\n",
            "1.66% of the tokens in the testing data is not in the training data (excluding the start symbol)\n"
          ]
        }
      ],
      "source": [
        "# before mapping words to <unk> in train ot test data\n",
        "from collections import Counter\n",
        "frequency_test = Counter(test_words)\n",
        "# print(len(frequency_test))\n",
        "start_token_count = frequency_test['<s>']\n",
        "#print(start_token_count)\n",
        "token_count_ex_start_test = len(test_words) - start_token_count\n",
        "total_word_type = len(list(frequency_test.keys()))\n",
        "word_type_ex_start_test = total_word_type-1\n",
        "\n",
        "# word types not appeared in training data\n",
        "train_word_type = list(unique_words.keys())\n",
        "test_word_type = list(frequency_test.keys())\n",
        "test_word_not_in_training = list(set(test_word_type) - set(train_word_type))\n",
        "\n",
        "\n",
        "a1 = len(test_word_not_in_training)/word_type_ex_start_test\n",
        "a2 = sum(frequency_test[word] for word in test_word_not_in_training)/token_count_ex_start_test\n",
        "print(\"{:.2%}\".format(a1), \"of word types in the testing data is not in the training data (excluding the start symbol)\")\n",
        "print(\"{:.2%}\".format(a2), \"of the tokens in the testing data is not in the training data (excluding the start symbol)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07rMZ_X_Cihm"
      },
      "source": [
        "### Question 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace words appeared once in training with <unk>\n",
        "trained_words_unk = []\n",
        "for word in trained_words:\n",
        "    if word in unk_words:\n",
        "        trained_words_unk.append('<unk>')\n",
        "    else:\n",
        "        trained_words_unk.append(word)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "JgoZfDoTB0A1",
        "outputId": "c68425ca-5c18-4d48-aa87-31853e993edb"
      },
      "outputs": [],
      "source": [
        "# replace test words not in training to unk\n",
        "# trained_words_unk = list(map(lambda x: '<unk>' if x in unk_words else x, trained_words))\n",
        "test_word_not_in_training_2 = list(set(test_word_type) - set(trained_words_unk))\n",
        "test_words_unk = list(map(lambda x: '<unk>' if x in test_word_not_in_training_2 else x, test_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YPhd9dGZENci"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 731347 bigram types in the training data\n",
            "There are 2368210 bigrams in the training data\n",
            "There are 2300 bigram types in the test data\n",
            "There are 2669 bigrams in the test data\n"
          ]
        }
      ],
      "source": [
        "# create bigram dictionary for the training data\n",
        "bigram_train = {}\n",
        "for i in range(len(trained_words_unk)-1):\n",
        "    if trained_words_unk[i] != '<s>' and trained_words_unk[i+1] != '<s>':\n",
        "        bigram = (trained_words_unk[i], trained_words_unk[i+1])\n",
        "        if bigram not in bigram_train.keys():\n",
        "            bigram_train[bigram] = 1\n",
        "        else: \n",
        "            bigram_train[bigram] += 1\n",
        "# create bigram dictionary for the test data\n",
        "bigram_test = {}\n",
        "for i in range(len(test_words_unk)-1):\n",
        "    if test_words_unk[i] != '<s>' and test_words_unk[i+1] != '<s>':\n",
        "        bigram = (test_words_unk[i], test_words_unk[i+1])\n",
        "        if bigram not in bigram_test.keys():\n",
        "            bigram_test[bigram] = 1\n",
        "        else:\n",
        "            bigram_test[bigram] += 1\n",
        "\n",
        "print(\"There are\", len(bigram_train), \"bigram types in the training data\")\n",
        "print(\"There are\", sum(bigram_train.values()), \"bigrams in the training data\")\n",
        "print(\"There are\", len(bigram_test), \"bigram types in the test data\")\n",
        "print(\"There are\", sum(bigram_test.values()), \"bigrams in the test data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 25.87% percent of bigram types in the test data not in the training data\n",
            "There are 22.37% percent of bigram tokens in the test data not in the training data\n"
          ]
        }
      ],
      "source": [
        "# calculate percentage of bigram types in the test data not in the training data \n",
        "diff_bitypes = list(set(bigram_test.keys()) - set(bigram_train.keys()))\n",
        "bitype_diff_count = len(diff_bitypes)\n",
        "bitype_diff_perc = bitype_diff_count/len(bigram_test)\n",
        "# calculate percentage of bigram tokens in the test data not in the training data \n",
        "bitoken_diff_perc = sum([bigram_test[gram] for gram in diff_bitypes])/sum(bigram_test.values())\n",
        "\n",
        "print(\"There are\", \"{:.2%}\".format(bitype_diff_perc), \"percent of bigram types in the test data not in the training data\")\n",
        "print(\"There are\", \"{:.2%}\".format(bitoken_diff_perc), \"percent of bigram tokens in the test data not in the training data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s>', 'i', 'look', 'forward', 'to', 'hearing', 'your', 'reply', '</s>']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_sentence = 'I look forward to hearing your reply.'\n",
        "tokenized_test = test_sentence.strip(punctuation).lower().split(' ')\n",
        "# Pad the sentence with begin and end symbols\n",
        "tokenized_test = ['<s>'] + tokenized_test + ['</s>']\n",
        "tokenized_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dictionary for every word type and its count for the training data after <unk> is implemented\n",
        "train_word_type_dict = Counter(trained_words_unk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<s>', 'i', 'look', 'forward', 'to', 'hearing', 'your', 'reply', '</s>']\n"
          ]
        }
      ],
      "source": [
        "# replace unigrams in the test sentence not in the training data with <unk>\n",
        "for i in range(len(tokenized_test)):\n",
        "    if tokenized_test[i] not in train_word_type_dict.keys():\n",
        "        tokenized_test[i] = '<unk>'\n",
        "print(tokenized_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Unigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The log probability of the sentence under unigram model is: -90.06992741329718\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# calculate the log probability of the sentence using unigram model\n",
        "def log_unigram_prob(train_word_type_dict, test):\n",
        "    total_token_in_train = sum(train_word_type_dict.values())\n",
        "    sentence_prob = 1\n",
        "    for token in test:\n",
        "        count_of_token = train_word_type_dict[token]\n",
        "        prob_of_token = count_of_token/total_token_in_train\n",
        "        #print(\"The probability of having token\", token, \"in the sentence is\", prob_of_token)\n",
        "        sentence_prob *= prob_of_token\n",
        "    log_sen_prob = np.log2(sentence_prob)\n",
        "    return log_sen_prob\n",
        "unigram_probability = log_unigram_prob(train_word_type_dict, tokenized_test)\n",
        "print(\"The log probability of the sentence under unigram model is:\", unigram_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#convert training text into a dictionary of bigrams \n",
        "bigram_train_2 = {}\n",
        "for i in range(len(trained_words_unk)-1):\n",
        "        bigram = (trained_words_unk[i], trained_words_unk[i+1])\n",
        "        if bigram not in bigram_train_2.keys():\n",
        "            bigram_train_2[bigram] = 1\n",
        "        else: \n",
        "            bigram_train_2[bigram] += 1\n",
        "\n",
        "#convert test sentence into a list of bigrams\n",
        "bigram_test_2 = []\n",
        "for i in range(len(tokenized_test)-1):\n",
        "        bigram = (tokenized_test[i], tokenized_test[i+1])\n",
        "        bigram_test_2.append(bigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following paramter has 0 value: P ('hearing', 'your')\n",
            "The log probability of the sentence under the bigram model is 0\n"
          ]
        }
      ],
      "source": [
        "# calculate the log probability of the sentence under the bigram model\n",
        "def log_bigram_prob(train_bigram_dict, train_unigram_dict, test_bigram_list):\n",
        "    sentence_prob = 1\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram not in train_bigram_dict.keys():\n",
        "            print(\"The following paramter has 0 value:\", \"P\", bigram)\n",
        "            return 0\n",
        "        else:\n",
        "            prob_of_bigram = train_bigram_dict[bigram]/train_unigram_dict[bigram[0]]\n",
        "            sentence_prob *= prob_of_bigram\n",
        "    return np.log2(sentence_prob)\n",
        "\n",
        "bigram_probability = log_bigram_prob(bigram_train_2, train_word_type_dict, bigram_test_2)\n",
        "print(\"The log probability of the sentence under the bigram model is\", bigram_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bigram Model with Add-one Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The log probability of the sentence under the bigram model with add one smoothing is 0\n"
          ]
        }
      ],
      "source": [
        "# calculate the log probability of the sentence under the bigram model with add one smoothing\n",
        "def log_bigram_smoothed(train_bigram_dict, train_unigram_dict, test_bigram_list):\n",
        "    sentence_prob = 1\n",
        "    V = len(train_unigram_dict)\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram not in train_bigram_dict.keys():\n",
        "            numerator = 0\n",
        "        else:\n",
        "            numerator = train_bigram_dict[bigram]\n",
        "        prob_of_bigram = (numerator+1)/(train_unigram_dict[bigram[0]]+V)\n",
        "        sentence_prob += np.log2(prob_of_bigram)\n",
        "    return sentence_prob\n",
        "\n",
        "log_bigram_smoothed_probability = log_bigram_smoothed(bigram_train_2, train_word_type_dict, bigram_test_2)\n",
        "print(\"The log probability of the sentence under the bigram model with add one smoothing is\", bigram_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Katz Backoff + Discounting on Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing bigrams: {'hearing': {'your'}, 'your': {'reply'}, 'reply': {'</s>'}}\n",
            "alpha: {'hearing': 0.18660287081339713, 'your': 0.28142974527526704, 'reply': 0.23076923076923078}\n",
            "The log probability of the sentence under the bigram model with .5 discounting is -40.46781489609892\n"
          ]
        }
      ],
      "source": [
        "def discounted_backoff_bigram(discount_value, train_bigram_dict, train_unigram_dict, test_bigram_list):\n",
        "    sentence_prob = 1\n",
        "    missing_bigram_base_words = {}\n",
        "    alpha = {}\n",
        "    # first find all the missing bigram's base words in the test data\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram not in train_bigram_dict.keys():\n",
        "            w0 = bigram[0]\n",
        "            wi = bigram[1]\n",
        "            if w0 not in missing_bigram_base_words.keys():\n",
        "                missing_bigram_base_words[w0] = {wi}\n",
        "            else:\n",
        "                missing_bigram_base_words[w0].add(wi)\n",
        "    print(\"Missing bigrams:\", missing_bigram_base_words)\n",
        "    # calcualte alpha for each base word 0\n",
        "    for w0 in missing_bigram_base_words.keys():\n",
        "        total_base_word_count = train_unigram_dict[w0]\n",
        "        total_discounts = sum([discount_value for key in train_bigram_dict.keys() if key[0] == w0])\n",
        "        alpha[w0] = total_discounts/total_base_word_count\n",
        "    print('alpha:', alpha)\n",
        "    # Now calculate the probabilities for each bigram\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram[0] not in missing_bigram_base_words.keys() and bigram in train_bigram_dict.keys():\n",
        "            bigram_prob = train_bigram_dict[bigram]/train_unigram_dict[bigram[0]]\n",
        "            sentence_prob *= bigram_prob\n",
        "        if bigram[0] in missing_bigram_base_words.keys() and bigram in train_bigram_dict.keys():\n",
        "            bigram_prob = (train_bigram_dict[bigram]-discount_value)/train_unigram_dict[bigram[0]]\n",
        "            sentence_prob *= bigram_prob\n",
        "        if bigram[0] in missing_bigram_base_words.keys() and bigram not in train_bigram_dict.keys():\n",
        "            w0 = bigram[0]\n",
        "            wi = bigram[1]\n",
        "            unigram_prob_numerator = train_unigram_dict[wi]/sum(train_unigram_dict.values())\n",
        "            unigram_prob_denominator = sum([train_unigram_dict[x] for x in missing_bigram_base_words[w0]])/sum(train_unigram_dict.values())\n",
        "            bigram_prob = alpha[bigram[0]] * unigram_prob_numerator/unigram_prob_denominator\n",
        "            sentence_prob *= bigram_prob\n",
        "\n",
        "    return np.log2(sentence_prob)\n",
        "\n",
        "discounting_bigram_probability = discounted_backoff_bigram(0.5, bigram_train_2, train_word_type_dict, bigram_test_2)\n",
        "print(\"The log probability of the sentence under the bigram model with .5 discounting is\", discounting_bigram_probability)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Perplexity of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity under the unigram model is 1029.5296845225253\n"
          ]
        }
      ],
      "source": [
        "# Perplexity of the sentence under the unigram model\n",
        "def pp_unigram(train_word_type_dict, test):\n",
        "    total_token_in_train = sum(train_word_type_dict.values())\n",
        "    wordtype_test_count = len(test)\n",
        "    Sum = 0\n",
        "    for token in test:\n",
        "        count_of_token = train_word_type_dict[token]\n",
        "        prob_of_token = count_of_token/total_token_in_train\n",
        "        Sum += np.log2(prob_of_token)\n",
        "    perplexity = 2**(-Sum/wordtype_test_count)\n",
        "    return perplexity\n",
        "unigram_perplecity = pp_unigram(train_word_type_dict, tokenized_test)\n",
        "print(\"Perplexity under the unigram model is\", unigram_perplecity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity under the bigram model is inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/vc/6cpgd0gd3d53rklf_fz231y80000gn/T/ipykernel_74313/284501343.py:7: RuntimeWarning: divide by zero encountered in log2\n",
            "  log_prob_of_bigram = np.log2(prob_of_bigram)\n"
          ]
        }
      ],
      "source": [
        "# Perplexity of the sentence under the bigram model\n",
        "def pp_bigram(train_bigram_dict, train_unigram_dict, test_bigram_list, bigram_test_count):\n",
        "    Sum = 0\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram not in train_bigram_dict.keys():\n",
        "            prob_of_bigram = 0\n",
        "            log_prob_of_bigram = np.log2(prob_of_bigram)\n",
        "            Sum += log_prob_of_bigram\n",
        "\n",
        "        else:\n",
        "            prob_of_bigram = train_bigram_dict[bigram]/train_unigram_dict[bigram[0]]\n",
        "            log_prob_of_bigram = np.log2(prob_of_bigram)\n",
        "            Sum += log_prob_of_bigram\n",
        "    perplexity = 2**(-Sum/bigram_test_count)\n",
        "    return perplexity\n",
        "\n",
        "bigram_perplexity = pp_bigram(bigram_train_2, train_word_type_dict, bigram_test_2, len(bigram_test_2))\n",
        "print(\"Perplexity under the bigram model is\", bigram_perplexity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity under the bigram model with add one smoothing is 4275.263017416363\n"
          ]
        }
      ],
      "source": [
        "def pp_bigram_smoothed(train_bigram_dict, train_unigram_dict, test_bigram_list, bigram_test_count):\n",
        "    Sum = 0\n",
        "    V = len(train_unigram_dict)\n",
        "    for bigram in test_bigram_list:\n",
        "        numerator = 0 if bigram not in train_bigram_dict.keys() else train_bigram_dict[bigram]\n",
        "        prob_of_bigram = (numerator+1)/(train_unigram_dict[bigram[0]]+V)\n",
        "        log_prob_of_bigram = np.log2(prob_of_bigram)\n",
        "        Sum += log_prob_of_bigram\n",
        "    perplexity = 2**(-Sum/bigram_test_count)\n",
        "    return perplexity\n",
        "\n",
        "bigram_perplexity_smoothed = pp_bigram_smoothed(bigram_train_2, train_word_type_dict, bigram_test_2, len(bigram_test_2))\n",
        "print(\"Perplexity under the bigram model with add one smoothing is\", bigram_perplexity_smoothed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Perplexity of the bigram model with discounting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The perplexity of the bigram model with discounting is: 33.323703974856386\n"
          ]
        }
      ],
      "source": [
        "def pp_bigram_dicounted(discount_value, train_bigram_dict, train_unigram_dict, test_bigram_list, bigram_test_count):\n",
        "    missing_bigram_base_words = {}\n",
        "    alpha = {}\n",
        "    Sum = 0\n",
        "    # first find all the missing bigram's base words in the test data\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram not in train_bigram_dict.keys():\n",
        "            w0 = bigram[0]\n",
        "            wi = bigram[1]\n",
        "            if w0 not in missing_bigram_base_words.keys():\n",
        "                missing_bigram_base_words[w0] = {wi}\n",
        "            else:\n",
        "                missing_bigram_base_words[w0].add(wi)\n",
        "   #print(\"Missing bigrams:\", missing_bigram_base_words)\n",
        "    # calcualte alpha for each base word 0\n",
        "    for w0 in missing_bigram_base_words.keys():\n",
        "        total_base_word_count = train_unigram_dict[w0]\n",
        "        total_discounts = sum([discount_value for key in train_bigram_dict.keys() if key[0] == w0])\n",
        "        alpha[w0] = total_discounts/total_base_word_count\n",
        "    #print('alpha:', alpha)\n",
        "    # Now calculate the probabilities for each bigram\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram[0] not in missing_bigram_base_words.keys() and bigram in train_bigram_dict.keys():\n",
        "            bigram_prob = train_bigram_dict[bigram]/train_unigram_dict[bigram[0]]\n",
        "            Sum += np.log2(bigram_prob)\n",
        "        if bigram[0] in missing_bigram_base_words.keys() and bigram in train_bigram_dict.keys():\n",
        "            bigram_prob = (train_bigram_dict[bigram]-discount_value)/train_unigram_dict[bigram[0]]\n",
        "            Sum += np.log2(bigram_prob)\n",
        "        if bigram[0] in missing_bigram_base_words.keys() and bigram not in train_bigram_dict.keys():\n",
        "            w0 = bigram[0]\n",
        "            wi = bigram[1]\n",
        "            unigram_prob_numerator = train_unigram_dict[wi]/sum(train_unigram_dict.values())\n",
        "            unigram_prob_denominator = sum([train_unigram_dict[x] for x in missing_bigram_base_words[w0]])/sum(train_unigram_dict.values())\n",
        "            bigram_prob = alpha[bigram[0]] * unigram_prob_numerator/unigram_prob_denominator\n",
        "            Sum += np.log2(bigram_prob)\n",
        "    perplexity = 2**(-Sum/(bigram_test_count))\n",
        "    return perplexity\n",
        "\n",
        "bigram_dicounted_perplexity = pp_bigram_dicounted(0.5, bigram_train_2, train_word_type_dict, bigram_test_2, len(bigram_test_2))\n",
        "print(\"The perplexity of the bigram model with discounting is:\",bigram_dicounted_perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# further ensure all unique words to the test corpus is converted to <unk>\n",
        "for i in range(len(test_words_unk)):\n",
        "    if test_words_unk[i] not in train_word_type_dict.keys():\n",
        "        test_words_unk[i] = '<unk>'\n",
        "    else:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For the padded test corpus, spplit it into sentences, make sure eveything is lowercased and all unique words to the test data is <unk>\n",
        "test_corpus_sentences = []\n",
        "for sentence in test_data_padded:\n",
        "    sentence = sentence.lower()\n",
        "    new_sentence = []\n",
        "    for unigram in sentence.split(' '):\n",
        "        if unigram not in train_word_type_dict.keys():\n",
        "            unigram = '<unk>'\n",
        "            new_sentence.append(unigram)\n",
        "        else:\n",
        "            new_sentence.append(unigram)\n",
        "    test_corpus_sentences.append(' '.join(new_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All the varibales needed \n",
        "## Test corpus unigram dictionary\n",
        "test_unigram_dict = {}\n",
        "for token in test_words_unk:\n",
        "    if token not in test_unigram_dict.keys():\n",
        "        test_unigram_dict[token] = 1\n",
        "    else:\n",
        "        test_unigram_dict[token] += 1\n",
        "\n",
        "## Test corpus bigram list\n",
        "test_corpus_bigrams = []\n",
        "for i in range(len(test_words_unk)-1):\n",
        "    bigram = (test_words_unk[i], test_words_unk[i+1])\n",
        "    test_corpus_bigrams.append(bigram)\n",
        "    \n",
        "## Test corpus bigram dictionary\n",
        "test_corpus_bigrams_dict = {}\n",
        "for i in range(len(test_words_unk)-1):\n",
        "    bigram = (test_words_unk[i], test_words_unk[i+1])\n",
        "    if bigram not in test_corpus_bigrams_dict.keys():\n",
        "        test_corpus_bigrams_dict[bigram] = 1\n",
        "    else:\n",
        "        test_corpus_bigrams_dict[bigram] += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Perplexity of the test corpus under unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity of the test corpus under the unigram model is 1000.2124621763647\n"
          ]
        }
      ],
      "source": [
        "def pp_corpus_unigram(train_word_type_dict, test_courpus_sentences, test_unigram_dict):\n",
        "    total_token_in_train = sum(train_word_type_dict.values())\n",
        "    test_unigram_count = sum(test_unigram_dict.values())\n",
        "    Sum = 0\n",
        "    for sentence in test_courpus_sentences:\n",
        "        sentence_prob = 0\n",
        "        unigrams = sentence.split(' ')\n",
        "        for unigram in unigrams:\n",
        "            log_prob_of_unigram = np.log2(train_word_type_dict[unigram]/total_token_in_train)\n",
        "            sentence_prob += log_prob_of_unigram\n",
        "        Sum += sentence_prob\n",
        "    perplexity = 2**(-Sum/test_unigram_count)\n",
        "    return perplexity\n",
        "unigram_perplecity = pp_corpus_unigram(train_word_type_dict, test_corpus_sentences, test_unigram_dict)\n",
        "print(\"Perplexity of the test corpus under the unigram model is\", unigram_perplecity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Perplexity of the entire test corpus under bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The perplexity of the test corpus under bigram model is: inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/vc/6cpgd0gd3d53rklf_fz231y80000gn/T/ipykernel_74313/1200326676.py:9: RuntimeWarning: divide by zero encountered in log2\n",
            "  prob_of_bigram = np.log2(0)\n"
          ]
        }
      ],
      "source": [
        "def pp_bigram_corpus(train_bigram_dict, train_unigram_dict, test_courpus_sentences, bigram_test_count):\n",
        "    Sum = 0\n",
        "    for sentence in test_courpus_sentences:\n",
        "        words = sentence.split(' ')\n",
        "        sentence_bigram_list = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
        "        sentence_prob = 0\n",
        "        for bigram in sentence_bigram_list:\n",
        "            if bigram not in train_bigram_dict.keys():\n",
        "                prob_of_bigram = np.log2(0)\n",
        "                sentence_prob += prob_of_bigram\n",
        "\n",
        "            else:\n",
        "                prob_of_bigram = np.log2(train_bigram_dict[bigram]/train_unigram_dict[bigram[0]])\n",
        "                sentence_prob += prob_of_bigram\n",
        "        Sum += sentence_prob\n",
        "    perplexity = 2**(-Sum/bigram_test_count)\n",
        "    return perplexity\n",
        "\n",
        "test_perplexity_bigram = pp_bigram_corpus(bigram_train_2, train_word_type_dict, test_corpus_sentences, len(test_corpus_bigrams))\n",
        "print(\"The perplexity of the test corpus under bigram model is:\", test_perplexity_bigram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Under bigram model with Add-one smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The perplexity of the test corpus under bigram model with add one smoothing is: 323.68678658337\n"
          ]
        }
      ],
      "source": [
        "def pp_bigram_corpus_smoothed(train_bigram_dict, train_unigram_dict, test_courpus_sentences, bigram_test_count, unique_bigram_test_count):\n",
        "    Sum = 0\n",
        "    V = unique_bigram_test_count\n",
        "    for sentence in test_courpus_sentences:\n",
        "        words = sentence.split(' ')\n",
        "        sentence_bigram_list = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
        "        sentence_prob = 0\n",
        "        for bigram in sentence_bigram_list:\n",
        "            if bigram not in train_bigram_dict.keys():\n",
        "                numerator = 1\n",
        "                log_prob_of_bigram = np.log2(numerator/(train_unigram_dict[bigram[0]]+V))\n",
        "                sentence_prob += log_prob_of_bigram\n",
        "\n",
        "            else:\n",
        "                log_prob_of_bigram = np.log2((train_bigram_dict[bigram]+1)/(train_unigram_dict[bigram[0]]+V))\n",
        "                sentence_prob += log_prob_of_bigram\n",
        "        Sum += sentence_prob\n",
        "        #print(Sum)\n",
        "    perplexity = 2**(-Sum/bigram_test_count)\n",
        "    return perplexity\n",
        "test_corpus_perplexity_bigram_smoothed = pp_bigram_corpus_smoothed(bigram_train_2, train_word_type_dict, test_corpus_sentences, len(test_corpus_bigrams), len(test_corpus_bigrams_dict))\n",
        "print(\"The perplexity of the test corpus under bigram model with add one smoothing is:\", test_corpus_perplexity_bigram_smoothed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Under bigram with discounting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity of the test corpus under bigram model with discounting is: 43.55225431918881\n"
          ]
        }
      ],
      "source": [
        "def pp_bigram_dicounted_corpus(discount_value, train_bigram_dict, train_unigram_dict, test_bigram_list, test_data_padded, bigram_test_count):\n",
        "    missing_bigram_base_words = {}\n",
        "    alpha = {}\n",
        "    Sum = 0\n",
        "    # first find all the missing bigram's base words in the test data\n",
        "    for bigram in test_bigram_list:\n",
        "        if bigram not in train_bigram_dict.keys():\n",
        "            w0 = bigram[0]\n",
        "            wi = bigram[1]\n",
        "            if w0 not in missing_bigram_base_words.keys():\n",
        "                missing_bigram_base_words[w0] = {wi}\n",
        "            else:\n",
        "                missing_bigram_base_words[w0].add(wi)\n",
        "    # print(\"Missing bigrams:\", missing_bigram_base_words)\n",
        "    # calcualte alpha for each base word 0\n",
        "    for w0 in missing_bigram_base_words.keys():\n",
        "        total_base_word_count = train_unigram_dict[w0]\n",
        "        if total_base_word_count == 0:\n",
        "            print(w0)\n",
        "        total_discounts = sum([discount_value*1 for key in train_bigram_dict.keys() if key[0] == w0])\n",
        "        alpha[w0] = total_discounts/total_base_word_count\n",
        "    # print('alpha:', alpha)\n",
        "    # Now calculate the probabilities for each bigram\n",
        "    for sentence in test_data_padded:\n",
        "        words = sentence.split(' ')\n",
        "        sentence_bigram_list = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
        "        sentence_prob = 0      \n",
        "        for bigram in sentence_bigram_list:\n",
        "            if bigram[0] not in missing_bigram_base_words.keys() and bigram in train_bigram_dict.keys():\n",
        "                bigram_prob = np.log2(train_bigram_dict[bigram]/train_unigram_dict[bigram[0]])\n",
        "                sentence_prob += bigram_prob\n",
        "            if bigram[0] in missing_bigram_base_words.keys() and bigram in train_bigram_dict.keys():\n",
        "                bigram_prob = np.log2((train_bigram_dict[bigram]-discount_value)/train_unigram_dict[bigram[0]])\n",
        "                sentence_prob += bigram_prob\n",
        "            if bigram[0] in missing_bigram_base_words.keys() and bigram not in train_bigram_dict.keys():\n",
        "                w0 = bigram[0]\n",
        "                wi = bigram[1]\n",
        "                unigram_prob_numerator = train_unigram_dict[wi]/sum(train_unigram_dict.values())\n",
        "                unigram_prob_denominator = sum([(train_unigram_dict[x]/sum(train_unigram_dict.values())) for x in missing_bigram_base_words[w0]])\n",
        "                bigram_prob = np.log2(alpha[w0] * unigram_prob_numerator/unigram_prob_denominator)\n",
        "                sentence_prob += bigram_prob\n",
        "        Sum += sentence_prob\n",
        "    perplexity = 2**(-Sum/bigram_test_count)\n",
        "    return perplexity\n",
        "\n",
        "perplexity_test_corpus_discounted = pp_bigram_dicounted_corpus(.5, bigram_train_2, train_word_type_dict, \n",
        "test_corpus_bigrams, test_corpus_sentences, len(test_corpus_bigrams))\n",
        "print(\"Perplexity of the test corpus under bigram model with discounting is:\",perplexity_test_corpus_discounted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_HW1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
